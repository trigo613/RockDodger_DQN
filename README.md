# DQN Agent Trained to Play a Custom Game

This project trains a Deep Q-Network (DQN) agent using visual input only to play a small custom game created at the beginning of the notebook.

## Training Results

The agent's progress is shown below after 200, 400, and 600 rounds of training.

<table>
  <tr>
    <td><h4>After 200 Rounds</h4></td>
    <td><h4>After 400 Rounds</h4></td>
    <td><h4>After 600 Rounds</h4></td>
  </tr>
  <tr>
    <td><img src="https://github.com/user-attachments/assets/0170e7fa-6b9f-4e9a-a4ab-5f80ae211e25" alt="output200" width="300"/></td>
    <td><img src="https://github.com/user-attachments/assets/601fd27f-5cc0-4e4c-9172-9808b777ae6e" alt="output400" width="300"/></td>
    <td><img src="https://github.com/user-attachments/assets/246e1a64-800f-48f5-bec7-5dc8e56ba953" alt="output600" width="300"/></td>
  </tr>
</table>

## How it Works

The DQN agent is trained using a convolutional neural network (CNN) to process the visual input of the game environment. Over time, the agent learns to optimize its actions and improve its performance in the game.
